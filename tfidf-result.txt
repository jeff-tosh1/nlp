-----A01F0055.trn1-----
1位:(68行目)それから特にえ八か月児において先程申し上げたようなえーえーと長調の原型への選好あるいは長調と短調のえ弁別の度合いとそれから経験との関連が示唆されたことからゼロ歳児の後期において経験の影響が加わることによってこの長調の原型への選好ですとか調の弁別だとかそういうものが形作られ始めるという可能性が示されました

2位:(52行目)で十四か月児におけるえ聴取時間平均はえ原型の方が七．七三秒変形が六．三五秒だったんですけれどもえこの群においてのみえー原型への選好がえー有意に認められました

3位:(12行目)で長調短調のえー旋律の形態における違いえー旋律としてのそのー長調短調の違いに気付くのはいつ頃からなのか本研究では童謡の旋律を用いてえーまず第一段階の検討として長調の原型旋律とそれを短調に変えた変形旋律を乳児に示して選好聴取反応を検討してみました

4位:(63行目)よいしょよいしょえまず長調の原型とその短調の変形を弁別してかつ原型の方へえー選好が有意に認められたのはえー十四か月児であったと判断できます

5位:(67行目)変形を有意に聞いたという人数比を見ますと五か月児ではえーやはり特に差はないんですけれども十四か月児に向かって徐々にどうも長調の原型への選好がえー形作られているのではないかということが予想されます

-----A01M0007.trn1-----
1位:(38行目)でこの場合はこの音声単位に相当するのはコンテキスト依存モデルと言いましてまー基本的には音素なんですがえーと色んな一つの音素でも例えばアクセント核があるとかあるいはモーラのどの辺モーラ位置によるとかあるいは前がどんなぼあえー音素であるとかか色んな要因がある訳ですからえーとそれのそれらの要因を全て考えたようなえーコンテキスト依存モデル作っておいまず最初に学習でしておいて作っておくとで後はテキストが入ってきたらそのコンテキストベーストのラベルシークエンスにしてそれをずっと並べてそこからパラメーター生成を行なってえー後は合成するとでまでこのコンテキスト依存モデルなんですがあのーコンテキストというのはえートライホンつっあ先行音素と後続音素だけ考えただけでももうかなり膨大な数で更にピッチのことをあるいは品詞とか品詞情報とかえーモーラ位置情報とか文の長さの情報とか全部考えると物凄い膨大な量になりますのでえーそれぞれに対応したえーモデルを全部用意するするのはちょっと不可能実現不可能そこでどうやってるかと言うとまコンテキストクラスタリングを使いましてえーとそれぞれスペクトルあるいはピッチあるいは継続長でえーディシジョンツリーを作って決定木をつ作っておきましてでま学習データーにないようなコンテキストが現われても必ずどこかのどっかからえー引っ張ってこれるという風な形を取ってる

2位:(53行目)まかなりあのー元の話者性に近い音が出てるかと後例の最後ですがえーと話者照照合システムの安全性ま今までそのー話者照合システムの安全性っていうのはあんまり検討されてなかったと言うかあの人間の詐称者に対してはま尤度正規化等の方法を取ればまー殆ど大丈夫だよというようなことが言われて後録音音声に対してはまテキスト指定型をのシステム作れば大丈夫だよというようなことが言われてむ合成音声に対してはあまり検討されてなかったんですがま最近合成音声に対してどういうどれくらい安全かっていうのがあのーここんい去年のあえアイシーエスエルピーとか今年のアアイキャスプユーロスピーチでもあのー他の研究者が何件か発表してましたけどもま合成音声のおー質が良くなってきたんでまこれも検討する必要があるだろうとでま我々がやった実験ていうのはあのーわテキスト指定型でえーとまー条件としてはその合成側と認識側の条件が違ってた方が現実的だろうということで合成側はメルケプストラムで合成してえーと認識側の話者照合システムの認識側の方はエルピーシーケプストラムでえー音響パラメーターを取って照合したとで実際には元はこういうまこういう音を入れるとまこの人はそうだよということなんですがま我々がやった実験でまー実は合成音ピッチ情報全部落としちゃって全部ぬいはっ白色ノイズであのー励振したような音を使ってその詐称の実験をやってみました

3位:(35行目)でそれに対してまー我々が取ったアプローチというのはんーま有声音はま一次元空間からの観測事象でえー何か連続なえー出力分布を持ってるところからのえー観測であるとえそれから無声音はゼロ次元空間からの観測事象であるとでそれがまこれむい有声音と無声音が常に同時にどっちから起こるか分からないけども同時に観測できてまーただ観測できる時はどっちか一方だけは観測できるとしてまエイチエムエムの方もえーと有声音用の分布と無声音用のえーとぶんこここっちはもうゼロ次元ですから分布はないんですけどもま二つの空間を持っていてですそれぞれの空間には重みが付いててで有声音の方でが観測しつされたらそれをいつえー適当なし出力分布でえー近似してやるとで無声音が観測されたらそのとところは重みえーだけをえー学習しておくとで実際に今度はここういうエイチエムまー我々エムエスディーエイチエムエムとゆん呼んでるんですが多空間上のエイチエムエムでモデル化しといてえーこれを実際に今度はパラメーター生成を行なう際にはえーこちらの重みが大きいか小さいかによって有声無声を区間を選んでやって有声区間であれば先程のえー動的特徴量を考慮したパラメーター生成法によってえーピッチパターンを生成してやるとで無声区間の方が確率が高ければそこは無声としてやるというようなあー生成方法を取っています

4位:(51行目)えーとだいぶ時間がもう押してきたんですが後は認識ボコーダーこれはあえー入力音声を音声認識を掛けてピッチと音声おんしょ音素系列とえーじぞ継続時間だけを送るということでまー非常に数百ビットぐらいというあー数百ビット・パー・セックという非非常に低いレーレートで音声の符号化が行なえるという訳ですがえこれもあのーあの同じここで持ってるえーおエイチエムエムの人の声しか出せないという訳でこれもやはりえー適応を掛けることによって色んな人の声を出したいとでこれはその例なんですが例えば入力音声としてこういう声が入ってきた時にえーと不特定話者モデルで音を作るとま話者性が殆ど失われてるんですがそれに対してま百ビット・パー・セックぐらいで話者情報送ってやることによっておっとごめんなさい

5位:(29行目)えーまず音声データーベースからメルケプストラム分析行ないましてえーメルケプストラムとそれの動的特徴量デルタとデルタデルタを求めたいとで後は音素ごとにえーエイチエムエムを学習しまして今度は入力テキストを与えられたらそのえ音素系列に従ってえー音声エイチエムエムをこうずらっと並べて一つのおっきな一つの文章のエイチエムエムを作るとで後はここから先程い述べましたえーパラメーター系列の生成法によってメルケプストラムを出力して後それに対して適当なピッチを与えてエムエルエスエーフィルターを励振してやって合成音声とするとえーとじゃまずどんな音が出たかというのを聞いていただきます

-----A01M0048.trn1-----
1位:(53行目)アントレインドワーズ実在する英単語しえー訓練に使われなかったものと後無意味単語の方ですがえー大体二十ポイントから三十ポイントの上昇率ですから解釈としてはえー訓練には使用されなかったアイテムに対してもプリテストよりもポストテストの方が二十から三十ポイント正答率が良いという汎化を示しているものだと考えます

2位:(14行目)えー例えば日本人はシラブルというものを知らない訳ですからコンセプトがないものを数えさせてもどうえーと結果としてどういう解釈ができるのかまたえーシラブルという英語シラブルの構造のえ定義のようなものをえーま口頭あるいは紙面ですれば十分なのではないかというこいう意見もあるとは思いますが我々のアプローチとしては聴覚訓練によって英語音声英語音声に出現するえーシラブルがどういうものかという言わばセンスのようなものを掴むことが可能であろうというアプローチです

3位:(15行目)えーこれまで行なった先行研究では実在する英単語を使ってえー日本人の英語シラブルを数えた時の正答率というのは五十七パーセントと比較的低いということが分かっています

4位:(54行目)こちらがえーシラブルの構造無意味単語のシラブルの構造一つ一つの要因を取ってえーそれぞれえー構造の要因が変化していくにつれてプリテストとポストテストでどういうえー正答率が変化していくかというのを示したものです

5位:(39行目)最後にポストテストですがポストテストはプリテストと同じようにフィードバックは与えずに四名のうちの二名が発話したえー全ての刺激四十八の無意味単語と五十二の実在英単語を使用しました

-----A01M0133.trn1-----
1位:(10行目)でこの現象のえー順応音のえー順応音をですね二成分よりなる複合音としてえーまそれらの成分間のえー周波数変調方向の組み合わせとえー成分間の距離を要因としてえーこれらがえー周波数変化残効に及ぼすええー影響からえー帯域間の相互作用を検討していこうというのが本研究の目的です

2位:(44行目)で距離が近い時にはえー残効量が減少しえー遠くなると残効量が増加したということからえー成分間の距離によってま変調を抑制したり変調のコーディングを抑制したり促進したりするようなえーメカニズムがあるとですから帯域ごとに何かインターラクションがあるだけではなくてその結び付きがえーれま帯域の距離によってえー違うのではないかということです

3位:(41行目)で一つはえー単に他の帯域に何か音が存在するとかえーま物理的な変調が存在するということではなくえー二つのえー順応成分の一致不一致に従って相互作用が見られたということです

4位:(29行目)でえーえーでそれぞれの中でえー順応音の二つの成分のうち千ヘルツじゃない方のえー変化方向ごとに残効量をプロットしてます

5位:(1行目)でこのような帯域間の変調を比較するメカニズムについてはえーまグルーピングのキューとしてエフエムが本当に有効なのかどうかえーつまりえー異なる帯域の成分を一つの音源としてまとめる時にそのー変調のえー一貫性がえーま手掛かりとして重要であるという主張に対してえーまそれが本当にえー聴覚系で実現できるのかという観点からこれまで検討されてきました

-----A01M0142.trn1-----
1位:(45行目)で方法三では無音区間の湧き出しがほぼゼロとなりましたけれどもおー正解精度がいちるいくす著しく低下したということになりましたがこの原因としてはえー有音エイチエムエムの中に入力フレームとマッチしないようなエイチエムエムが方法三では学習されてしまったと風に考えております

2位:(38行目)で緑のものが無音区間にぜん音節の全区間があー湧き出す誤りのカウント数ですけれどもえーっとその従従来方法一方法二方法三とま制約を強めるに従ってえうまー期待通り湧き出し誤りはま減少してるとただしそのエルとかアールという量で見るとそれ程差はん方法二方法三になるとまーえー急激にまえー無音があー無音の挿入がす減少するという結果になりました

3位:(30行目)これによって学習時に紛れ込んできたマスク値のサンプルに対応するような分布を排除するうーことができあえーこのエイチエムエムは無音区間とマッチングすることがなくなるであろうということを考えて考えましたとでこれが方法これを方法三といたします

4位:(27行目)んでえー学習データー・入力データー共マスク値で置き換えたえーそのこおーことによりましてえー無音区間に期待する効果としては無音区間にえー有音のエイチエムエムがマッチマッチングすることを防ぐというま考えでまー考えんんで考えです

5位:(50行目)えー正規化アールエムエス値・有音無音判別結果・マスク処理等をま併用を試みましたがえー無音部への湧き出し誤りの減少を確認したにとどまりまして正解精度の向上は見られませんでした

-----A02F0038.trn1-----
1位:(44行目)この型の語は四十八語で全体の十一分の一と少ないことから連用形名詞は原則として動詞の動作作用の意味を受け継ぐものと考えられこれは連用形名詞の意味について動詞句の意味がそのまま無限定的に動作することという意で名詞化するという国立国語研究所一九八五や基本的には何々すること即ち動作作用そのものを指す意味に名詞化されるという西尾一九八八の指摘通りの傾向と言えます

2位:(52行目)これは分類語彙表に動詞連用形単独で採録されているものの名詞としての用法が文脈によって臨時的に成り立ったり合成語の成分になることで動詞の意味を受け継ぐというものです

3位:(17行目)全桁・三桁一致の語は二百六十六語あり連用形名詞が動詞の意味を受け継いでいることが読み取れる一方一桁一致や不一致の語も二百三十五語あり意味のずれも少なくないと判断できます

4位:(131行目)俯瞰的な視点から連用形名詞と動詞の意味の重なりずれを確認し個々の語に当たりながら全重複型拡張増加型分離型など六パターンにずれ方を類型しました

5位:(16行目)連用形名詞と動詞の両者が採録されていた五百九十一組の語について意味概念が上位である左側の桁から照合して一致度を調べたところ結果は次の表の通りでした

-----A02M0098.trn1-----
1位:(31行目)築島裕千九百六十さくねん三年他一括弧漢文訓読語は当時の日常会話語でなくして文章語の一種う当時の日常会話語に基づいて書かれたと考えられるところの仮名日記や物語二括弧今日我々が普通に用いている語彙で源氏物語に見えず訓点だけに見えるものがまことに多いことが分かるのである

2位:(42行目)えー問題点について一括弧和文語と目されているものの中に訓点資料にも見える語が少ないとは言えないことでえー時間の関係でえー傍線部下線部に飛びますがえー二二形対立のもののうち慈恩伝古点にも平仮名えー山形あーえ括弧の中仮名文学作品のものおーのものが四割強見出だされる

3位:(59行目)えー二行目三行目でございますが工匠家来楫取おうけいえー世界の人おーこれらにい漢文訓読語が用いられた例が括弧五から括弧十三であります

4位:(37行目)しかし二括弧源氏物語や枕草子などの仮名文学作品では現代語の密かにに相当する語形がみそかにであるが平安初期以来の漢文訓読にには密かにが使用されている漢文訓読の語彙は基底社会方言にいー基づいているからである

5位:(71行目)えー二括弧えー地の文には漢文訓読語と和文語が拮抗して用いられますが四で取り上げたような二形対立に類するものの中には意味の相違が明確に認められるものがございます

-----A03M0004.trn1-----
1位:(43行目)えつまり最年少のという意味的重要部分は削除されてしまいますがえ主語述語のような日本語らしさは維持されているのがとっこの日本語らしさのみを判断基準にした場合の要約えーの特徴であります

2位:(34行目)えーこれから実際の要約例を示していきますがえそれはまず日本語らしさのみを用いた場合の要約例そして次に意味的重要度のみをえー判断基準とした場合の要約例えそして最後に日本語らしさと意味的重要度という二つのえー基準を用いた場合のえ三つの要約例を示しその違いを説明していきたいと思います

3位:(58行目)え実際に評価したものはえ日本語らしさのみを判断基準にした場合のものえー意味的重要度のみを判断基準にした場合のものえー日本語らしさと意味的重要度の二つの基準を用いた場合えまた比較といたしましてえ左から一文節ずつ削除する場合えランダムで一文節ずつ削除する場合の合計五つを評価いたしました

4位:(50行目)えでは最後にえー日本語らしさと意味的重要度という二つの判断基準を用いた要約例について説明します

5位:(40行目)えこのようにして要約していく訳ですがえ次に削除される最年少のというものはえ要約対象文を見ていただくと分かるのですがえこの文の内容を表わした意味的重要度の高い文だと考えられます

-----A05M0002.trn1-----
1位:(7行目)それから片っ方で見られるその判決であるとか国会であるとかそういう漢語の頭高化というのはこれはえー漢語の平板という全体像の中でえー特異的にいー頭高になっているので余計これはあのみんなが耳障りにすなるんではないかということでこれはまーあの一つそのーしゅ方向としてですねえー漢語の頭高化があるということではなさそうだといううー今のところのおー感触を持っています

2位:(9行目)でこれについて私共はあーずざっとしたところでこれもあの皆さん方との御相談なんですがえーどうもその東京の出身者というのがアナウンサーの中に何人かいる訳ですが両親共にえ東京といううー人間いますがこの人間の方がそのアクセント変化を早く取り入れているんですね

3位:(24行目)で後もう一つはそのーこの文発話について色々なことが言われていますけれども日本語のそのーアアクセントについて語のアクセントについてはい色々と御研究があーせ先行研究研究そそれこそえー山のようにある訳ですがイントネーションについて日本語のイントネーションどうあるべきなのか特に外国人教える場合どうなのかあるいは日本人同士の正しい喋り方はどうなのかといった場合のイントネーション論については殆ど言及がないんですね

4位:(12行目)ですからこれ今までそのアクセントというのはかなりブロック的な大きさあるいは県ぐらいのレベルで見てたんですけれどもこれからはあのーアメダスあるいはその今の地震のサイズモじゃないですけれどももっと細かいメッシュで見ていくと案外そのどこが発信地なのかどっからどういう形で伝染していくのかっていうのが見えるやもしれません

5位:(14行目)それから文発話について色々そのーんー問題が出ておりまして例えば今あの朝やっている三宅というアナウンサーがあれが多分エヌエイチケーのアナウンサーの中で一番早くえー半疑問形を使った人間ではないかと思っておりますがえーまさにあれは癖で抜けないんですね

-----A11M0369.trn1-----
1位:(70行目)えティーエス二ケーあ話し言葉ティーエス二ケーピーティーエム二ケーなどの話し言葉から作成したモデルとアイピーエーのモデルを比較すると話し言葉から作成したモデルの方が高い認識率となっていてえー話し言葉から作成したモデルが有効であることが分かります

2位:(104行目)ティーエスいっえー三ケーエー二二などティーエス三ケーが最も良くなる講演の数が一番お多いですがえーエヌゼロ七などティーエス一．五千五百状態のモデルが一番良くなる講演もありました

3位:(123行目)えーあなおこちらの図でえー発話速度上位六割に絞ったモデルで学習時間が学習データー量が減少し六割に減少してるにもかかわらず全体として認識率が下がらなかった理由としてえー学会講演からなるテストセットであるのテストセットが学会講演であるのに対して発話速度が上位六割の講演を選ぶと主に模擬講演が取り除かれ学会講演が多く残ることが理由の一つとして考えられます

4位:(92行目)えー一万語のモデルと二万語のモデルの認識率の差はおよそ零．五パーセント程度二万語のモデルと三万語のモデルの差は零．二五パーセント程度となりました

5位:(65行目)スポンとえーウェブを比較するとんどの講演に対してもスポンの方が高い認識率となっていて話し言葉コーパスから作成したモデルが有効であることが分かります

