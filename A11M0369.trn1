え××××××××××××××××××について東工大の××が発表します
発表の内容は従来のモデルとの比較あーあかっき書き言葉に基づく従来のモデルと話し言葉コーパスを用いたモデルの比較えーっと後話し言葉コーパスを利用したモデルの検討の二点です
使用したコーパスは話し言葉コーパスとウェブコーパスです
え話し言葉コーパスは二千年十二月の時点で書き起こしの存在した六百十講演を対象としています
えー六百十講演の内訳は模擬講演が三百三十六講演音響学会が百三十九講演言語処理学会が六十三講演その他が七十二講演となっています
ウェブコーパスは当研究室でえーウェブ上から集めた講演の書き起こしテキストです
こちらはえー文章として編集されてえフィラーなどは取り除かれてしまっています
えー話題はえー社会問題や回顧録など一般的な内容となっています
んテストセットは話し言葉コーパス中の十講演を用いました
え全て男性話者です
データー名称は一人の話者による一つの講演に対応しています
えここでは簡単の為に第二列に示す略称を用います
初めの四講演は日本音響学会または音声学会で音声に関連した内容です
えこれらはきょあー配布された共通のテストセットです
各講演の講演時間はこのようになっています
話し方には個人差があります
この図は単位時間当たりの形態素数で見た発話速度です
えピー二五の発話速度は一秒間当たりえー約四．三形態素となっています
エー二二やピー二五エスゼロ五の発話速度の速くエー二三やケーゼロ五が比較的あこのじゅこの十講演の中では比較的ゆっくりであるということが分かります
え発話の流暢さとしてフィラーの頻度と言い直しの頻度を示したのがこの図です
縦棒で示しているのがフィラーの頻度です
えーエー二二やピー二五エスゼロ五ので頻度が高いことが分かります
折れ線で示したものが言い直しの頻度です
エー二二やエスゼロ五で頻度が高いことが分かります
また全体としてフィラーの頻度と言い直しの頻度を比較するとフィラーの頻度の方が高いという特徴があります
実験条件ですが音声は十六キロヘルツで標本化十六ビットで量子化を行ないました
えー認識に使用した発話の単位は書き起こし中のラベルを元に五百ミリ秒の無音を基準としました
音響パラメーターはエムエフシーシー十二次元デルカとプラスデルタケプストラム十二次元対数エネルギー一次差分の合計二十五次元です
発話単位でシーエムエスを行ないました
えー音響モデルの学習にはエイチティーケーんバージョン二．二を用いました
形態素解析んにはジェータグを使用しました
音声認識デコーダーにはジュリウス三．一を用いました
えー発表の前半の内容として従来のモデルとの比較についんおいん前半として従来のモデルとの比較について説明します
言語モデルについてはウェブコーパスから作成したモデルと話し言葉コーパスから作成した音響モデルあーモデルの比較を行ないました
えー音響モデルに関してはアイピーエーのによるよみえ読み上げ音声を元にしたモデルと話し言葉コーパスの男性部分から作成したモデルの比較を行ないました
言語モデルについて説明します
スポンは話し言葉コーパス中のか講演などの書き起こしテキストからえー作成したえーん言語モデルです
ウェブはんウェブコーパスから作成したしたモデルです
えーえっとこのウェブコーパスはフィラーなどは取り除かれてしまっているのでえーテキストの段階で補正を行ないました
ウェブエスピーはえう話題適応の目的でこのウェブのコーパスに音声の教科書をテキストの段階で合わせてから作成したモデルです
えあ後ぬこのススポンですが読点は転記単位の間に補いました
各言語モデルの概概要を表に示します
えースポンの学習形態素数は約一．五メガウェブが二メガウェブエスピーがこの二メガプラス教科書の分の零．零六メガです
語彙数は全て二万語です
言語モデルの性能としてしてパープレキシティーと未知語率を示します
縦棒で示したのがパープレキシティーです
えーウェブとウェブエスピーを比較すると全体としてあまり変わらないことが分かります
えウェブとスポンを比較するとスポンの方が低いパープレキシティーとなっています
折れ線で示したものは未知語率です
えウェブとウェブエスピーを比較すると音声の内容は発話の内容が音声に関連した左側の四つの講演で特に未知語率の改善が大きいことが分かります
またウェブエスピーとスポンを比較するとスポンの方が低いパープレキシティーとなっています
これはスポンんの学習セットにえ学会講演が含まれていることと発話のスタイルが話し言葉であることによる為です
音響モデルについて説明します
ピーティーエム二ケーティーエス二ケーは話し言葉コーパスから作成したモデルです
アイピーエー二ケーはえアイピーエーんによるやや読み上げ音声四十時間分から作成した作成されたモデルです
全て男性モデルをです
えピーティーエム二ケーはえーおフォネティックタイドミクスチャーモデルでえ二千状態のトライホンを元にしたえ百二十九状態のモデルです
混合数は六十四時間学習データー量は五十く話し言葉コーパスの五十九五十九時間分です
ティーエス二ケーは通常の状態共有のトライホンでえ状態数がんん二千混合数十六です
え学習データーはここちらとん同じものです
アイピーエー二ケーは二千状態十六混合のものを使用しました
え認識実験んです
おんえ言語モルッと言語モデルと認識率の関係を示します
音響モデルはティーエス二ケーを使用しました
スポンとえーウェブを比較するとんどの講演に対してもスポンの方が高い認識率となっていて話し言葉コーパスから作成したモデルが有効であることが分かります
ウェブとウェブエスピーを比較するとえーウェブエスピーの方が高い認識率なっていて教科書を加える音声の教科書を加える話題適応が有効であることが分かります
また先程のパープレキシティーと未知語率のえ結果からこの改善は主に未知語率の改善によるものです
音響モデルと認識率の関係を示します
言語モデルにはスポンを使用しました
えティーエス二ケーあ話し言葉ティーエス二ケーピーティーエム二ケーなどの話し言葉から作成したモデルとアイピーエーのモデルを比較すると話し言葉から作成したモデルの方が高い認識率となっていてえー話し言葉から作成したモデルが有効であることが分かります
えまたティーエス二ケーとピーティーエム二ケーを比較するとえー通常の状態共有モデルティーエス二ケーの方が高い認識率となりました
えー発表の後半の内容として話し言葉コーパスを利用したモデルの検討について説明します
えー音響モデルに関しては状態数と認識率発話スタイルの影響とその対応教師なし話者適応化について検討を行ないました
言語モデルについては語彙数と未知語率認識率の関係やパープレキシティーなどについて検討を行ないました
言語モデルについて説明します
えー使用したデーターは全て話し言葉コーパスの六百十講演一．五メガ形態素です
えー語彙数やカットオフ方法コンテキストの長さを変えたこのような言語モデルを用意しました
ブイ十ケーは語彙数がえーい十ケーでんカットオフは行なわれ行なっていません
えそれえーんの二グラムと逆向きトライグラムからなっています
ブイ三十ケーシーゼロ一は語彙数が三十ケーでトライグラムのカットオフをい一えとしたモデルです
えーまた参考としてえい四グラムと五グラムを用意しました
音響モデルについて説明します
えー話し言葉コーパスの男性音声部分から作成しました
ティーエス一．五ケーティーエス二ケーティーエス三ケーはそれぞれ状態数が一．五ケー二ケー三ケーの状態共有モデルです
んティーエスエフ二ケーはえーこのな中の発話速度が上位六割となる講演を選んできて作成したモデルです
えその為学習データー量はえ三十六時間となっています
ティーエスティー三ケーはえーええーティーエス三ケーとほぼ同等なのですが第一状態から第三状態へのスキップ遷移を加えたモデルです
えー言語モデルの語彙数と未知語率の関係を示します
え一万語のモデルと二万語のモデルの未知語率のえー差はえおよそ一．四パーセント程度二万語のモデルと三万語のモデルの差はえーれ零．五パーセント程度です
三万語のモデルの未知語率はえおよそ一．三パーセント程度です
え言語モデルの語彙数と認識率の関係を示します
えー一万語のモデルと二万語のモデルの認識率の差はおよそ零．五パーセント程度二万語のモデルと三万語のモデルの差は零．二五パーセント程度となりました
え語彙数三万語の言語モデルについてえーこれらの言語モデルについてパープレキシティーを示します
え一番左ががバイグラムで右側がえートライグラムですがトえートライグラムの効果がはっきり出ていることが分かります
えトライグラムえーカットオフを行なわないトライグラムとえートラつトライグラムのカットオフを一としたえーモデルの比較を行なうとこちらの方がえーやや低いパープレキシティーとなりました
えこれはカットオフいんによるスムージングの効果の為です
えートライグラムとえ四グラムを比較するとえーほぼ同じ程度のパープレキシティーとなりました
若干こちらが高めな程度です
えー四グラムと五グラムを比較するとえん五グラムの方が高いパープレキシティーとなりました
えなおえー四グラムや五グラムはカットオフを一としています
えー音響モデルの状態数と認識率の関係にを示します
言語モデルはブイ三十ケーを使用しました
えーどのモデルが良いかは講演によって異なります
ティーエスいっえー三ケーエー二二などティーエス三ケーが最も良くなる講演の数が一番お多いですがえーエヌゼロ七などティーエス一．五千五百状態のモデルが一番良くなる講演もありました
えあまた全えーとー全体として認識率に個人差が大きいことが分かります
発話速度とえーえこの図は発話速度と認識率の関係を示したものです
音響モデルはティーエス三ケー言語モデルはブイ三十ケーシーゼロ一を使用しました
えー横軸がえー発話速度縦軸が認識率です
各点は一つの講演に対応しています
またこれらの点にフィットさせた直線を重ねて示します
えー形態素数が多いあ発話速度が速い講演で認識率が低いことが分かります
相関係数はマイナス零．四一となりました
えフィラー頻度と認識率の関係を示します
フィラー頻度の高い講演で認識率が低い傾向があることが分かります
えーは発話速度のへの対応の検討としてえこちら側の図ではえーティーエス二ケーとティーエスエフ二ケーを比較しました
えーティーエス二ケーはえーティーエスエフ二ケーは発話速度が上位六割の講演を選んで学習したモデルです
発話速度の速いエー二二で若干認識率が上がっていますがピー二五では逆に下がっています
またそれ程速くないエー二三で多少上がってるなど期待した効果は得られませんでした
こちら側の図はえーティーエス三ケーとティーエスティー三ケーを比較したものです
ティーエスティー三えーどちらも三状態のレフト・トゥー・ライトですがティーエスティー三ケーはえー第一状態から第三状態へのスキップ遷移を加えたものです
こちらはスキップ遷移はありません
えこちらも全体としてまほぼ同程度の認識率となり期待した効果は得られませんでした
えーあなおこちらの図でえー発話速度上位六割に絞ったモデルで学習時間が学習データー量が減少し六割に減少してるにもかかわらず全体として認識率が下がらなかった理由としてえー学会講演からなるテストセットであるのテストセットが学会講演であるのに対して発話速度が上位六割の講演を選ぶと主に模擬講演が取り除かれ学会講演が多く残ることが理由の一つとして考えられます
え教師なし話者適応化の実験について説明します
適応化方法ですがえまず不特定話者モデルでかっテストセットの各講演を認識します
え得られたえー認識結果を正解文のえー近似として用いてエムエルエルアールを用いてえー各話者にえ各講演に各話者に対する適応化を行ないました
得られたえー話者依存エイチエムエムを用いてえー各講演を再度に認識しえ認識率を求めました
え更にえこのようにして得られたえー認識結果をも使ってもう一度話者適応化を行なった実験も行ないました
え教師なし話者適応化の効果です
言語モデルにはブイ三十ケーシーゼロ一を使用しました
えー元にした不特定話者モデルはティーエス三ケーで一回教師なし適応を行なったモデルがエムエルエルアール二回行なったものがエムエルエルアールアイ二です
えーティーエス三ケーとエムエルエルアールで認識率の差は三パーセントから四パーセント程度エムエルエルアールとエムエルエルアールアイ二でえ認識率の差は一パーセント程度となりました
えーこエムエルエルアールアイ二を用いた場合のえーこの四人の平均の認識率は七十一パーセント程度となりました
え最後に講演音声認識のえーまとめと課題とし課題です
まとめとして話し言葉コーパスを用いたモデルの有効性が示せました
えーこ認識率の個人差が大きいことが分かりました
発話速度が速くフィラーや言い直しが多い話者で認識率が低い傾向がありました
音響モデルの教師なし話者適応化が有効であることが分かりました
講演音声認識のえー認識率は今のところ七十パーセント程度です
今後の課題としては話し方のスタイルや話題へん話題の変化への適応えー認識音声の認識理解を考慮した評価法の考案などが挙げられます
以上で発表を終わります
